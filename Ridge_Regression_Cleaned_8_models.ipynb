{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with Ridge Regression (8 models)\n",
    "\n",
    "In this notebook, we will use the functions in the file ridge_regression.py. This time, we will use the 8 data sets and see if the prediction becomes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import display\n",
    "# Import everything in the functions folder\n",
    "from functions.costs import *\n",
    "from functions.helpers import *\n",
    "from functions.split import *\n",
    "from functions.ridge_regression import *\n",
    "from functions.helpers import *\n",
    "from functions.least_squares_GD import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "\n",
    "\"\"\"\n",
    "TRAINING_DATA = ['train_jet_0_wout_mass_pca.csv' , 'train_jet_0_with_mass_pca.csv',\n",
    "                 'train_jet_1_wout_mass_pca.csv' , 'train_jet_1_with_mass_pca.csv',\n",
    "                 'train_jet_2_wout_mass_pca.csv' , 'train_jet_2_with_mass_pca.csv',\n",
    "                 'train_jet_3_wout_mass_pca.csv' , 'train_jet_3_with_mass_pca.csv']\n",
    "\n",
    "TEST_DATA = ['test_jet_0_wout_mass_pca.csv' , 'test_jet_0_with_mass_pca.csv',\n",
    "             'test_jet_1_wout_mass_pca.csv' , 'test_jet_1_with_mass_pca.csv',\n",
    "             'test_jet_2_wout_mass_pca.csv' , 'test_jet_2_with_mass_pca.csv',\n",
    "             'test_jet_3_wout_mass_pca.csv' , 'test_jet_3_with_mass_pca.csv']\n",
    "\"\"\"\n",
    "\n",
    "TRAINING_DATA = ['train_jet_0_wout_mass.csv' , 'train_jet_0_with_mass.csv',\n",
    "                 'train_jet_1_wout_mass.csv' , 'train_jet_1_with_mass.csv',\n",
    "                 'train_jet_2_wout_mass.csv' , 'train_jet_2_with_mass.csv',\n",
    "                 'train_jet_3_wout_mass.csv' , 'train_jet_3_with_mass.csv']\n",
    "\n",
    "TEST_DATA = ['test_jet_0_wout_mass.csv' , 'test_jet_0_with_mass.csv',\n",
    "             'test_jet_1_wout_mass.csv' , 'test_jet_1_with_mass.csv',\n",
    "             'test_jet_2_wout_mass.csv' , 'test_jet_2_with_mass.csv',\n",
    "             'test_jet_3_wout_mass.csv' , 'test_jet_3_with_mass.csv']\n",
    "\n",
    "degrees_poly = np.arange(1, 14)\n",
    "degrees_lambdas = np.arange(-10, 5)\n",
    "\n",
    "#degrees_poly = np.arange(5,6)\n",
    "#degrees_lambdas = np.arange(-2, 5)\n",
    "\n",
    "k_fold = 10\n",
    "digits = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on all the training data.\n",
    "We use CV to find best lambda and best degree and then we use the RR again to get the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation with file train_jet_0_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Max pred = 0.950804\n",
      "  Lambda* =  9.000e-06\n",
      "  Degree* = 12\n",
      "\n",
      "\n",
      "Cross-validation with file train_jet_0_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Max pred = 0.809840\n",
      "  Lambda* =  2.120e-02\n",
      "  Degree* = 9\n",
      "\n",
      "\n",
      "Cross-validation with file train_jet_1_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Max pred = 0.918651\n",
      "  Lambda* =  1.648e-05\n",
      "  Degree* = 7\n",
      "\n",
      "\n",
      "Cross-validation with file train_jet_1_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Max pred = 0.794441\n",
      "  Lambda* =  2.700e-04\n",
      "  Degree* = 9\n",
      "\n",
      "\n",
      "Cross-validation with file train_jet_2_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Max pred = 0.906780\n",
      "  Lambda* =  2.420e-06\n",
      "  Degree* = 10\n",
      "\n",
      "\n",
      "Cross-validation with file train_jet_2_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Max pred = 0.834247\n",
      "  Lambda* =  3.090e-04\n",
      "  Degree* = 10\n",
      "\n",
      "\n",
      "Cross-validation with file train_jet_3_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Max pred = 0.931973\n",
      "  Lambda* =  4.000e-05\n",
      "  Degree* = 8\n",
      "\n",
      "\n",
      "Cross-validation with file train_jet_3_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Max pred = 0.823259\n",
      "  Lambda* =  3.630e-10\n",
      "  Degree* = 9\n",
      "\n",
      "\n",
      "Percentage of right pred on training set: 0.831157\n"
     ]
    }
   ],
   "source": [
    "lambda_star = []\n",
    "degree_star = []\n",
    "perc_right_pred = 0\n",
    "nbr_labels = 0\n",
    "\n",
    "for data in TRAINING_DATA:\n",
    "    # Print that we start the training\n",
    "    print(\"Cross-validation with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    y_train, x_train, ids_train = load_csv_data(data_file)\n",
    "    #x_train, _, _ = standardize(x_train)\n",
    "    # Do the Cross Validation for the ridge regression\n",
    "    min_loss, deg, lamb = cross_validation(y_train, x_train, \n",
    "                                           degrees_lambdas, degrees_poly,\n",
    "                                           k_fold, digits, verbose = False)\n",
    "    # Print some interesting values\n",
    "    print(\"  Max pred = %f\"%(1-min_loss))\n",
    "    print(\"  Lambda* = %10.3e\"%lamb)\n",
    "    print(\"  Degree* = %i\"%deg)\n",
    "    print(\"\\n\")\n",
    "    lambda_star.append(lamb)\n",
    "    degree_star.append(deg)\n",
    "    # RR to get the best weights\n",
    "    tX_train = ct_poly(x_train, deg)\n",
    "    _, w_star = ridge_regression(y_train, tX_train, lamb)\n",
    "    weights.append(w_star)\n",
    "    \n",
    "    perc_right_pred += len(y_train)*(1-min_loss)\n",
    "    nbr_labels += len(y_train)\n",
    "    \n",
    "perc_right_pred = perc_right_pred/nbr_labels\n",
    "print(\"Percentage of right pred on training set: %f\"%perc_right_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the results into *pickle* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/degrees.p', 'wb') as pickle_file:\n",
    "    pickle.dump(degree_star, pickle_file)\n",
    "    \n",
    "with open('data/lambdas.p', 'wb') as pickle_file:\n",
    "    pickle.dump(lambda_star, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the results from the *pickle* files (in case we don't want to train again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/degrees.p', 'rb') as pickle_file:\n",
    "    degree_star = pickle.load(pickle_file)\n",
    "    \n",
    "with open('data/lambdas.p', 'rb') as pickle_file:\n",
    "    lambda_star = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 9, 7, 9, 10, 10, 8, 9]\n",
      "[9.0000000000000002e-06, 0.021199999999999997, 1.6479999999999998e-05, 0.00027000000000000006, 2.4199999999999997e-06, 0.00030899999999999998, 4.000000000000001e-05, 3.6299999999999999e-10]\n"
     ]
    }
   ],
   "source": [
    "print(degree_star)\n",
    "print(lambda_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the training (get the weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with file train_jet_0_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Good prediction: 24850/26123 (95.126900%)\n",
      "Wrong prediction: 1273/26123 (4.873100%)\n",
      "Training with file train_jet_0_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Good prediction: 60150/73789 (81.516215%)\n",
      "Wrong prediction: 13639/73789 (18.483785%)\n",
      "Training with file train_jet_1_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Good prediction: 7001/7562 (92.581328%)\n",
      "Wrong prediction: 561/7562 (7.418672%)\n",
      "Training with file train_jet_1_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Good prediction: 55904/69982 (79.883399%)\n",
      "Wrong prediction: 14078/69982 (20.116601%)\n",
      "Training with file train_jet_2_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Good prediction: 2952/2952 (100.000000%)\n",
      "Wrong prediction: 0/2952 (0.000000%)\n",
      "Training with file train_jet_2_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Good prediction: 39968/47427 (84.272672%)\n",
      "Wrong prediction: 7459/47427 (15.727328%)\n",
      "Training with file train_jet_3_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Good prediction: 1477/1477 (100.000000%)\n",
      "Wrong prediction: 0/1477 (0.000000%)\n",
      "Training with file train_jet_3_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Good prediction: 17379/20687 (84.009281%)\n",
      "Wrong prediction: 3308/20687 (15.990719%)\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "triplets = [1, 4, 6]\n",
    "for i in range(len(TRAINING_DATA)):\n",
    "    # Print that we start the training\n",
    "    print(\"Training with file %s\"%TRAINING_DATA[i])\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + TRAINING_DATA[i]\n",
    "    # Load the file\n",
    "    y_train, x_train, ids_train = load_csv_data(data_file)\n",
    "    \n",
    "    # RR to get the best weights\n",
    "    if i in triplets:\n",
    "        tX_train = ct_poly_triplet(x_train, degree_star[i])\n",
    "        _, w_star = ridge_regression(y_train, tX_train, lambda_star[i]) \n",
    "    else:\n",
    "        tX_train = ct_poly(x_train, degree_star[i])\n",
    "        _, w_star = ridge_regression(y_train, tX_train, lambda_star[i])   \n",
    "    prediction(y_train, tX_train, w_star)\n",
    "    weights.append(w_star)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on the test data to get the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with file test_jet_0_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_0_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_1_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_1_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_2_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_2_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_3_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_3_with_mass.csv\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "ids_pred = []\n",
    "\n",
    "for idx, data in enumerate(TEST_DATA):\n",
    "    # Print that we start the testing\n",
    "    print(\"Testing with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    _, x_test, ids_test = load_csv_data(data_file)\n",
    "    # Build the polynomial\n",
    "    if idx in triplets:\n",
    "        tX_test = ct_poly_triplet(x_test, degree_star[idx])\n",
    "    else:\n",
    "        tX_test = ct_poly(x_test, degree_star[idx])\n",
    "    \n",
    "    # Predict the labels\n",
    "    y_pred.append(predict_labels(weights[idx], tX_test)) \n",
    "    ids_pred.append(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "pred = []\n",
    "\n",
    "idx = min(ids_pred[:][0])\n",
    "\n",
    "length = np.sum(len(i) for i in y_pred)\n",
    "\n",
    "for i in range(length):\n",
    "    for j in range(len(TEST_DATA)):\n",
    "        if len(ids_pred[j]) > 0:\n",
    "            if ids_pred[j][0] == idx:\n",
    "                ids.append(idx)\n",
    "                pred.append(y_pred[j][0])\n",
    "                ids_pred[j] = np.delete(ids_pred[j], 0)\n",
    "                y_pred[j] = np.delete(y_pred[j], 0)\n",
    "                break\n",
    "\n",
    "    if (i % 100000 == 0):\n",
    "        print(i)\n",
    "        \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568238\n",
      "568238\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "ids = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output/RR_8_models_10_fold_ct_triplets.csv' # TODO: fill in desired name of output file for submission\n",
    "create_csv_submission(ids, pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32987938152675461"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred==1)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

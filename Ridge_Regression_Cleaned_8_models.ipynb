{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with Ridge Regression (8 models)\n",
    "\n",
    "In this notebook, we will use the functions in the file ridge_regression.py. This time, we will use the 8 data sets and see if the prediction becomes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import display\n",
    "# Import everything in the functions folder\n",
    "from functions.costs import *\n",
    "from functions.helpers import *\n",
    "from functions.split import *\n",
    "from functions.ridge_regression import *\n",
    "from functions.helpers import *\n",
    "from functions.least_squares_GD import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "\n",
    "TRAINING_DATA = ['train_jet_0_wout_mass.csv' , 'train_jet_0_with_mass.csv',\n",
    "                 'train_jet_1_wout_mass.csv' , 'train_jet_1_with_mass.csv',\n",
    "                 'train_jet_2_wout_mass.csv' , 'train_jet_2_with_mass.csv',\n",
    "                 'train_jet_3_wout_mass.csv' , 'train_jet_3_with_mass.csv']\n",
    "\n",
    "TEST_DATA = ['test_jet_0_wout_mass.csv' , 'test_jet_0_with_mass.csv',\n",
    "             'test_jet_1_wout_mass.csv' , 'test_jet_1_with_mass.csv',\n",
    "             'test_jet_2_wout_mass.csv' , 'test_jet_2_with_mass.csv',\n",
    "             'test_jet_3_wout_mass.csv' , 'test_jet_3_with_mass.csv']\n",
    "\n",
    "weights = []\n",
    "lambda_star = []\n",
    "degree_star = []\n",
    "y_pred = []\n",
    "ids_pred = []\n",
    "\n",
    "degrees_poly = np.arange(1, 14)\n",
    "degrees_lambdas = np.arange(-10, 5)\n",
    "\n",
    "k_fold = 10\n",
    "digits = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on all the training data.\n",
    "We use CV to find best lambda and best degree and then we use the RR again to get the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with file train_jet_0_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Min Loss = 0.049196\n",
      "  Lambda* =  9.000e-06\n",
      "  Degree* = 12\n",
      "\n",
      "\n",
      "Training with file train_jet_0_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Min Loss = 0.190160\n",
      "  Lambda* =  2.120e-02\n",
      "  Degree* = 9\n",
      "\n",
      "\n",
      "Training with file train_jet_1_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Min Loss = 0.081349\n",
      "  Lambda* =  1.648e-05\n",
      "  Degree* = 7\n",
      "\n",
      "\n",
      "Training with file train_jet_1_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Min Loss = 0.205559\n",
      "  Lambda* =  2.700e-04\n",
      "  Degree* = 9\n",
      "\n",
      "\n",
      "Training with file train_jet_2_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Min Loss = 0.093220\n",
      "  Lambda* =  2.420e-06\n",
      "  Degree* = 10\n",
      "\n",
      "\n",
      "Training with file train_jet_2_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Min Loss = 0.165753\n",
      "  Lambda* =  3.090e-04\n",
      "  Degree* = 10\n",
      "\n",
      "\n",
      "Training with file train_jet_3_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Min Loss = 0.068027\n",
      "  Lambda* =  4.000e-05\n",
      "  Degree* = 8\n",
      "\n",
      "\n",
      "Training with file train_jet_3_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Min Loss = 0.176741\n",
      "  Lambda* =  3.630e-10\n",
      "  Degree* = 9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in TRAINING_DATA:\n",
    "    # Print that we start the training\n",
    "    print(\"Training with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    y_train, x_train, ids_train = load_csv_data(data_file)\n",
    "    # Do the Cross Validation for the ridge regression\n",
    "    min_loss, deg, lamb = cross_validation(y_train, x_train, \n",
    "                                           degrees_lambdas, degrees_poly,\n",
    "                                           k_fold, digits, verbose = False)\n",
    "    # Print some interesting values\n",
    "    print(\"  Min Loss = %f\"%min_loss)\n",
    "    print(\"  Lambda* = %10.3e\"%lamb)\n",
    "    print(\"  Degree* = %i\"%deg)\n",
    "    print(\"\\n\")\n",
    "    lambda_star.append(lamb)\n",
    "    degree_star.append(deg)\n",
    "    # RR to get the best weights\n",
    "    if deg > 1:\n",
    "        tX_train = build_poly(x_train, deg)\n",
    "    else:\n",
    "        tX_train = x_train\n",
    "    _, w_star = ridge_regression(y_train, tX_train, lamb)\n",
    "    weights.append(w_star)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the results into *pickle* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/weights.p', 'wb') as pickle_file:\n",
    "    pickle.dump(weights, pickle_file)\n",
    "    \n",
    "with open('data/degrees.p', 'wb') as pickle_file:\n",
    "    pickle.dump(degree_star, pickle_file)\n",
    "    \n",
    "with open('data/lambdas.p', 'wb') as pickle_file:\n",
    "    pickle.dump(lambda_star, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the results from the *pickle* files (in case we don't want to train again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/weights.p', 'rb') as pickle_file:\n",
    "    weights = pickle.load(pickle_file)\n",
    "    \n",
    "with open('data/degrees.p', 'rb') as pickle_file:\n",
    "    degree_star = pickle.load(pickle_file)\n",
    "    \n",
    "with open('data/lambdas.p', 'rb') as pickle_file:\n",
    "    lambda_star = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on the test data to get the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with file test_jet_0_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_0_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_1_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_1_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_2_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_2_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_3_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_3_with_mass.csv\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(TEST_DATA):\n",
    "    # Print that we start the testing\n",
    "    print(\"Testing with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    _, x_test, ids_test = load_csv_data(data_file)\n",
    "    # Build the polynomial\n",
    "    if degree_star[idx] > 1:\n",
    "        tX_test = build_poly(x_test, degree_star[idx])\n",
    "    else:\n",
    "        tX_test = x_test\n",
    "    # Predict the labels\n",
    "    y_pred.append(predict_labels(weights[idx], tX_test))\n",
    "    ids_pred.append(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "pred = []\n",
    "\n",
    "idx = min(ids_pred[:][0])\n",
    "\n",
    "length = np.sum(len(i) for i in y_pred)\n",
    "\n",
    "for i in range(length):\n",
    "    for j in range(len(TEST_DATA)):\n",
    "        if len(ids_pred[j]) > 0:\n",
    "            if ids_pred[j][0] == idx:\n",
    "                ids.append(idx)\n",
    "                pred.append(y_pred[j][0])\n",
    "                ids_pred[j] = np.delete(ids_pred[j], 0)\n",
    "                y_pred[j] = np.delete(y_pred[j], 0)\n",
    "                break\n",
    "\n",
    "    if (i % 100000 == 0):\n",
    "        print(i)\n",
    "        \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568238\n",
      "568238\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "ids = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output/RR_8_models_10_fold.csv' # TODO: fill in desired name of output file for submission\n",
    "create_csv_submission(ids, pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32050478848651448"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred==1)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

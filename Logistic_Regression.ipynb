{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with Logistic Regression\n",
    "\n",
    "In this notebook, we will use the functions in the file logistic_regression.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import display\n",
    "# Import everything in the functions folder\n",
    "from functions.costs import *\n",
    "from functions.helpers import *\n",
    "from functions.split import *\n",
    "from functions.regularized_logistic_regression import *\n",
    "from functions.helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train_jet_0_with_mass.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tX, y = prepare_log_reg(tX, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data, just to see if we can predict something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "x_train, y_train, x_test, y_test = split_data(tX, y, ratio)\n",
    "x_train = x_train[:,1:]\n",
    "x_test = x_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degree = 10\n",
    "tX_train = build_poly(x_train, degree)\n",
    "tX_test = build_poly(x_test, degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the graph Loss vs Epochs while doing the Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=0, loss=1472767.8648400826, diff=1472767.8648400826\n",
      "Iter=100, loss=108608.81599506566, diff=-1364159.0488450169\n",
      "Iter=200, loss=51663.233521866445, diff=-56945.58247319921\n",
      "Iter=300, loss=60696.97542275965, diff=9033.741900893205\n",
      "Iter=400, loss=53985.58602702702, diff=-6711.389395732629\n",
      "Iter=500, loss=49766.18650621826, diff=-4219.399520808758\n",
      "Iter=600, loss=47281.86231322851, diff=-2484.324192989756\n",
      "Iter=700, loss=45817.374691892575, diff=-1464.4876213359312\n",
      "Iter=800, loss=44909.66452291739, diff=-907.7101689751871\n",
      "Iter=900, loss=44301.8541422578, diff=-607.81038065959\n",
      "Iter=1000, loss=43859.77297075529, diff=-442.08117150250473\n",
      "Iter=1100, loss=43514.37498994722, diff=-345.3979808080767\n",
      "Iter=1200, loss=43229.71506933918, diff=-284.65992060803546\n",
      "Iter=1300, loss=42986.47029607672, diff=-243.24477326246415\n",
      "Iter=1400, loss=42773.71423309, diff=-212.75606298671482\n",
      "Iter=1500, loss=42584.850320199024, diff=-188.8639128909781\n",
      "Iter=1600, loss=42415.593877357445, diff=-169.25644284157897\n",
      "Iter=1700, loss=42262.954464901544, diff=-152.63941245590104\n",
      "Iter=1800, loss=42124.70795394693, diff=-138.2465109546174\n",
      "Iter=1900, loss=41999.1117205723, diff=-125.59623337462835\n",
      "Iter=1999, loss=37804.163689668916, diff=-4194.9480309033825\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 100\n",
    "gamma = 1e-5\n",
    "lamb = 1\n",
    "\n",
    "# Initialization\n",
    "#losses, ws = regularized_logistic_regression(y_train, tX_train, gamma, lamb, max_iters, False, True)\n",
    "losses, ws = logistic_regression(y_train, tX_train, gamma, max_iters, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss = 33258.871285\n"
     ]
    }
   ],
   "source": [
    "w_star, min_loss = get_best_model(losses, ws)\n",
    "print(\"Min loss = %f\"%(min_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65906269  0.11911276  0.08493175 ...,  0.45895777  0.38278316\n",
      "  0.54839136]\n",
      "Good prediction: 10661/14758 (72.238786%)\n",
      "Wrong prediction: 4097/14758 (27.761214%)\n"
     ]
    }
   ],
   "source": [
    "prediction_log(y_test, tX_test, w_star)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:\n",
    "\n",
    "We retrain on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 600\n",
    "gamma = 1e-7\n",
    "\n",
    "# Initialization\n",
    "losses, ws = logistic_regression(y, tX, gamma, max_iters)\n",
    "w_star, min_loss = get_best_model(losses, ws)\n",
    "print(\"Min loss = %f\"%(min_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test, mean_tX_test, std_tX_test = standardize(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output/LR_GD.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w_star, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with Logistic Regression\n",
    "\n",
    "In this notebook, we will use the functions in the file logistic_regression.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import display\n",
    "# Import everything in the functions folder\n",
    "from functions.costs import *\n",
    "from functions.proj1_helpers import *\n",
    "from functions.split import *\n",
    "from functions.regularized_logistic_regression import *\n",
    "from functions.helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train_jet_0.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tX, y = prepare_log_reg(tX, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data, just to see if we can predict something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "x_train, y_train, x_test, y_test = split_data(tX, y, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degree = 10\n",
    "tX_train = build_poly(x_train, degree)\n",
    "tX_test = build_poly(x_test, degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the graph Loss vs Epochs while doing the Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iter=0, loss=18253217.94231841, diff=18253217.94231841\n",
      "  Iter=100, loss=1237851.5574030557, diff=-17015366.384915356\n",
      "  Iter=200, loss=3032748.7566503547, diff=1794897.199247299\n",
      "  Iter=300, loss=4207851.07015425, diff=1175102.313503895\n",
      "  Iter=400, loss=745745.5758945072, diff=-3462105.4942597426\n",
      "  Iter=500, loss=2512920.4030066137, diff=1767174.8271121066\n",
      "  Iter=600, loss=4093175.066861633, diff=1580254.6638550195\n",
      "  Iter=700, loss=676847.8804948468, diff=-3416327.1863667862\n",
      "  Iter=800, loss=2245730.148763059, diff=1568882.2682682122\n",
      "  Iter=900, loss=3965577.0874163383, diff=1719846.938653279\n",
      "  Iter=999, loss=603947.9896672246, diff=-3361629.0977491136\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 1000\n",
    "gamma = 1e-5\n",
    "lamb = 3\n",
    "\n",
    "# Initialization\n",
    "losses, ws = regularized_logistic_regression(y_train, tX_train, gamma, lamb, max_iters, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss = 483221.316172\n"
     ]
    }
   ],
   "source": [
    "w_star, min_loss = get_best_model(losses, ws)\n",
    "print(\"Min loss = %f\"%(min_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good prediction: 36563/50000 (73.126000%)\n",
      "Wrong prediction: 13437/50000 (26.874000%)\n"
     ]
    }
   ],
   "source": [
    "prediction_log(y_test, tX_test, w_star)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:\n",
    "\n",
    "We retrain on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 600\n",
    "gamma = 1e-7\n",
    "\n",
    "# Initialization\n",
    "losses, ws = logistic_regression(y, tX, gamma, max_iters)\n",
    "w_star, min_loss = get_best_model(losses, ws)\n",
    "print(\"Min loss = %f\"%(min_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test, mean_tX_test, std_tX_test = standardize(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output/LR_GD.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w_star, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

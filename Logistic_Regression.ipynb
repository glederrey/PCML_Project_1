{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with Logistic Regression\n",
    "\n",
    "In this notebook, we will use the functions in the file logistic_regression.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import display\n",
    "# Import everything in the functions folder\n",
    "from functions.costs import *\n",
    "from functions.proj1_helpers import *\n",
    "from functions.split import *\n",
    "from functions.regularized_logistic_regression import *\n",
    "from functions.helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train_jet_0.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tX, y = prepare_log_reg(tX, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data, just to see if we can predict something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "x_train, y_train, x_test, y_test = split_data(tX, y, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degree = 2\n",
    "tX_train = build_poly(x_train, degree)\n",
    "tX_test = build_poly(x_test, degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the graph Loss vs Epochs while doing the Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iter=0, loss=327655.77779208287, diff=327655.77779208287\n",
      "  Iter=100, loss=38032.29900531236, diff=-289623.4787867705\n",
      "  Iter=200, loss=35972.26584620967, diff=-2060.0331591026843\n",
      "  Iter=300, loss=35256.91953348131, diff=-715.3463127283612\n",
      "  Iter=400, loss=34916.4053713624, diff=-340.51416211891046\n",
      "  Iter=500, loss=34717.89937216304, diff=-198.50599919936212\n",
      "  Iter=600, loss=34587.08661311497, diff=-130.81275904807262\n",
      "  Iter=700, loss=34494.50364880016, diff=-92.58296431480994\n",
      "  Iter=800, loss=34426.1164275884, diff=-68.3872212117567\n",
      "  Iter=900, loss=34374.1724711948, diff=-51.943956393603\n",
      "  Iter=1000, loss=34333.90519819148, diff=-40.267273003315495\n",
      "  Iter=1100, loss=34302.169622095724, diff=-31.735576095758006\n",
      "  Iter=1200, loss=34276.79547447193, diff=-25.37414762379194\n",
      "  Iter=1300, loss=34256.24062372796, diff=-20.554850743974384\n",
      "  Iter=1400, loss=34239.386510601114, diff=-16.854113126843004\n",
      "  Iter=1500, loss=34225.40883952129, diff=-13.977671079825086\n",
      "  Iter=1600, loss=34213.69202989682, diff=-11.716809624471352\n",
      "  Iter=1700, loss=34203.77088826104, diff=-9.92114163577935\n",
      "  Iter=1800, loss=34195.29000319142, diff=-8.480885069620854\n",
      "  Iter=1900, loss=34187.97503438376, diff=-7.31496880765917\n",
      "  Iter=1999, loss=34181.671652671146, diff=-6.303381712612463\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 2000\n",
    "gamma = 1e-5\n",
    "lamb = 3\n",
    "\n",
    "# Initialization\n",
    "losses, ws = regularized_logistic_regression(y_train, tX_train, gamma, lamb, max_iters, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss = 34181.671653\n"
     ]
    }
   ],
   "source": [
    "w_star, min_loss = get_best_model(losses, ws)\n",
    "print(\"Min loss = %f\"%(min_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good prediction: 16024/19983 (80.188160%)\n",
      "Wrong prediction: 3959/19983 (19.811840%)\n"
     ]
    }
   ],
   "source": [
    "prediction_log(y_test, tX_test, w_star)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:\n",
    "\n",
    "We retrain on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 600\n",
    "gamma = 1e-7\n",
    "\n",
    "# Initialization\n",
    "losses, ws = logistic_regression(y, tX, gamma, max_iters)\n",
    "w_star, min_loss = get_best_model(losses, ws)\n",
    "print(\"Min loss = %f\"%(min_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test, mean_tX_test, std_tX_test = standardize(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output/LR_GD.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w_star, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

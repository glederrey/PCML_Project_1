{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with Ridge Regression (8 models)\n",
    "\n",
    "In this notebook, we will use the functions in the file ridge_regression.py. This time, we will use the 8 data sets and see if the prediction becomes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import display\n",
    "# Import everything in the functions folder\n",
    "from functions.costs import *\n",
    "from functions.split import *\n",
    "#from functions.ridge_regression import *\n",
    "from functions.helpers import *\n",
    "from functions.regularized_logistic_regression import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "\n",
    "TRAINING_DATA = ['train_jet_0_wout_mass.csv' , 'train_jet_0_with_mass.csv',\n",
    "                 'train_jet_1_wout_mass.csv' , 'train_jet_1_with_mass.csv',\n",
    "                 'train_jet_2_wout_mass.csv' , 'train_jet_2_with_mass.csv',\n",
    "                 'train_jet_3_wout_mass.csv' , 'train_jet_3_with_mass.csv']\n",
    "\n",
    "TEST_DATA = ['test_jet_0_wout_mass.csv' , 'test_jet_0_with_mass.csv',\n",
    "             'test_jet_1_wout_mass.csv' , 'test_jet_1_with_mass.csv',\n",
    "             'test_jet_2_wout_mass.csv' , 'test_jet_2_with_mass.csv',\n",
    "             'test_jet_3_wout_mass.csv' , 'test_jet_3_with_mass.csv']\n",
    "\n",
    "degrees_poly = np.arange(1, 4)\n",
    "degrees_lambdas = np.arange(-5, 5)\n",
    "\n",
    "#degrees_poly = np.arange(5,6)\n",
    "#degrees_lambdas = np.arange(-4, -2)\n",
    "\n",
    "k_fold = 4\n",
    "digits = 1\n",
    "max_iter = 1000\n",
    "gamma = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on all the training data.\n",
    "We use CV to find best lambda and best degree and then we use the RR again to get the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation with file train_jet_0_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Start the 4-fold Cross Validation!\n",
      "  Start degree 1\n",
      "    Power of lambda: -5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\helpers.py:255: RuntimeWarning: overflow encountered in exp\n",
      "  return np.sum(np.log(1+np.exp(np.dot(tx,w)))) - np.dot(y.transpose(),np.dot(tx,w))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Power of lambda: -4\n",
      "    Power of lambda: -3\n",
      "    Power of lambda: -2\n",
      "    Power of lambda: -1\n",
      "    Power of lambda: 0\n",
      "    Power of lambda: 1\n",
      "    Power of lambda: 2\n",
      "    Power of lambda: 3\n",
      "    Power of lambda: 4\n",
      "  Start for digit 1\n",
      "    Testing lambda =      5e-01\n",
      "    Testing lambda =      6e-01\n",
      "    Testing lambda =      7e-01\n",
      "    Testing lambda =      8e-01\n",
      "    Testing lambda =      9e-01\n",
      "    Testing lambda =      1e+00\n",
      "    Testing lambda =      2e+00\n",
      "    Testing lambda =      3e+00\n",
      "    Testing lambda =      4e+00\n",
      "    Testing lambda =      5e+00\n",
      "  Finished Degree 1. Best lambda is  4.000e+00 with percentage wrong pred 0.051953\n",
      "  --------------------\n",
      "  Start degree 2\n",
      "    Power of lambda: -5\n",
      "    Power of lambda: -4\n",
      "    Power of lambda: -3\n",
      "    Power of lambda: -2\n",
      "    Power of lambda: -1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-3ddf340b5eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                                            \u001b[0mdegrees_lambdas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegrees_poly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                            \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                            k_fold, digits, verbose = True)\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[1;31m# Print some interesting values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"  Max pred = %f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmin_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\regularized_logistic_regression.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, tx, deg_lambdas, degrees, gamma, max_iter, k_fold, digits, verbose, seed)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[1;31m# Loop on the k indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mw_star\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmats_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmats_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0mloss_te\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperc_wrong_pred_logit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmats_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_star\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\regularized_logistic_regression.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[0;34m(y, tx, lambda_, initial_w, max_iters, gamma, verbose)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[1;31m# Gradient descent method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_by_penalized_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[1;32mwhile\u001b[0m \u001b[0mcalculate_loss_reg_logit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgma\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mgma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgma\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_by_penalized_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\regularized_logistic_regression.py\u001b[0m in \u001b[0;36mcalculate_loss_reg_logit\u001b[0;34m(y, tx, w, lambda_)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_loss_reg_logit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mcalculate_loss_logit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpenalized_logistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\helpers.py\u001b[0m in \u001b[0;36mcalculate_loss_logit\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mCompute\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcost\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnegative\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mlikelihood\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mLogistic\u001b[0m \u001b[0mRegression\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLogit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_gradient_logit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambda_star = []\n",
    "degree_star = []\n",
    "perc_right_pred = 0\n",
    "nbr_labels = 0\n",
    "\n",
    "for idx, data in enumerate(TRAINING_DATA):\n",
    "    # Print that we start the training\n",
    "    print(\"Cross-validation with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    y_train, x_train, ids_train = load_csv_data(data_file)\n",
    "    x_train, y_train = prepare_logit(x_train, y_train)\n",
    "    # Do the Cross Validation for the ridge regression\n",
    "    min_loss, deg, lamb = cross_validation(y_train, x_train, \n",
    "                                           degrees_lambdas, degrees_poly,\n",
    "                                           gamma, max_iter,\n",
    "                                           k_fold, digits, verbose = True)\n",
    "    # Print some interesting values\n",
    "    print(\"  Max pred = %f\"%(1-min_loss))\n",
    "    print(\"  Lambda* = %10.3e\"%lamb)\n",
    "    print(\"  Degree* = %i\"%deg)\n",
    "    print(\"\\n\")\n",
    "    lambda_star.append(lamb)\n",
    "    degree_star.append(deg)\n",
    "    \n",
    "    perc_right_pred += len(y_train)*(1-min_loss)\n",
    "    nbr_labels += len(y_train)\n",
    "    \n",
    "perc_right_pred = perc_right_pred/nbr_labels\n",
    "print(\"Percentage of right pred on training set: %f\"%perc_right_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the results into *pickle* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/degrees_log.p', 'wb') as pickle_file:\n",
    "    pickle.dump(degree_star, pickle_file)\n",
    "    \n",
    "with open('data/lambdas_log.p', 'wb') as pickle_file:\n",
    "    pickle.dump(lambda_star, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the results from the *pickle* files (in case we don't want to train again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/degrees_log.p', 'rb') as pickle_file:\n",
    "    degree_star = pickle.load(pickle_file)\n",
    "    \n",
    "with open('data/lambdas_log.p', 'rb') as pickle_file:\n",
    "    lambda_star = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on the test data to get the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, data in enumerate(TEST_DATA):\n",
    "    # Print that we start the testing\n",
    "    print(\"Testing with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    _, x_test, ids_test = load_csv_data(data_file)\n",
    "    # Build the polynomial\n",
    "    if degree_star[idx] > 1:\n",
    "        tX_test = build_poly(x_test, degree_star[idx])\n",
    "    else:\n",
    "        tX_test = x_test\n",
    "    # Predict the labels\n",
    "    y_pred.append(predict_labels(weights[idx], tX_test))\n",
    "    ids_pred.append(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "pred = []\n",
    "\n",
    "idx = min(ids_pred[:][0])\n",
    "\n",
    "length = np.sum(len(i) for i in y_pred)\n",
    "\n",
    "for i in range(length):\n",
    "    for j in range(len(TEST_DATA)):\n",
    "        if len(ids_pred[j]) > 0:\n",
    "            if ids_pred[j][0] == idx:\n",
    "                ids.append(idx)\n",
    "                pred.append(y_pred[j][0])\n",
    "                ids_pred[j] = np.delete(ids_pred[j], 0)\n",
    "                y_pred[j] = np.delete(y_pred[j], 0)\n",
    "                break\n",
    "\n",
    "    if (i % 100000 == 0):\n",
    "        print(i)\n",
    "        \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(pred))\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "ids = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output/RR_8_models_10_fold.csv' # TODO: fill in desired name of output file for submission\n",
    "create_csv_submission(ids, pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(pred==1)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with Ridge Regression (8 models)\n",
    "\n",
    "In this notebook, we will use the functions in the file ridge_regression.py. This time, we will use the 8 data sets and see if the prediction becomes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import display\n",
    "# Import everything in the functions folder\n",
    "from functions.costs import *\n",
    "from functions.helpers import *\n",
    "from functions.split import *\n",
    "from functions.ridge_regression import *\n",
    "from functions.helpers import *\n",
    "from functions.least_squares_GD import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "\n",
    "TRAINING_DATA = ['train_jet_0_wout_mass.csv' , 'train_jet_0_with_mass.csv',\n",
    "                 'train_jet_1_wout_mass.csv' , 'train_jet_1_with_mass.csv',\n",
    "                 'train_jet_2_wout_mass.csv' , 'train_jet_2_with_mass.csv',\n",
    "                 'train_jet_3_wout_mass.csv' , 'train_jet_3_with_mass.csv']\n",
    "\n",
    "TEST_DATA = ['test_jet_0_wout_mass.csv' , 'test_jet_0_with_mass.csv',\n",
    "             'test_jet_1_wout_mass.csv' , 'test_jet_1_with_mass.csv',\n",
    "             'test_jet_2_wout_mass.csv' , 'test_jet_2_with_mass.csv',\n",
    "             'test_jet_3_wout_mass.csv' , 'test_jet_3_with_mass.csv']\n",
    "\n",
    "degrees_poly = np.arange(6, 14)\n",
    "degrees_lambdas = np.arange(-10, 5)\n",
    "\n",
    "#degrees_poly = np.arange(5,6)\n",
    "#degrees_lambdas = np.arange(-2, 5)\n",
    "\n",
    "k_fold = 10\n",
    "digits = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on all the training data.\n",
    "We use CV to find best lambda and best degree and then we use the RR again to get the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation with file train_jet_0_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Start the 10-fold Cross Validation!\n",
      "  Start degree 6\n",
      "  Finished Degree 6. Best lambda is  1.930e+04 with percentage wrong pred 0.049770\n",
      "  --------------------\n",
      "  Start degree 7\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'appen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32mD:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\ridge_regression.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, tx, deg_lambdas, degrees, k_fold, digits, verbose, seed)\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_star\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmats_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0milmbd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                         \u001b[0mloss_te\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperc_wrong_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmats_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_star\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\ridge_regression.py\u001b[0m in \u001b[0;36mridge_regression\u001b[0;34m(y, tx, lamb)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[1;31m# Compute optimal weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e7b7350d8b96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     min_loss, deg, lamb = cross_validation(y_train, x_train, \n\u001b[1;32m     17\u001b[0m                                            \u001b[0mdegrees_lambdas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegrees_poly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                            k_fold, digits, verbose = True)\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[1;31m# Print some interesting values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"  Max pred = %f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmin_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\ridge_regression.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, tx, deg_lambdas, degrees, k_fold, digits, verbose, seed)\u001b[0m\n\u001b[1;32m    117\u001b[0m                         \u001b[0mloss_te\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperc_wrong_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmats_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_star\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                         \u001b[0mloss_te\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mrmse_lmbd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0milmbd\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_te\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'appen'"
     ]
    }
   ],
   "source": [
    "lambda_star = []\n",
    "degree_star = []\n",
    "perc_right_pred = 0\n",
    "nbr_labels = 0\n",
    "\n",
    "for idx, data in enumerate(TRAINING_DATA):\n",
    "    # Print that we start the training\n",
    "    print(\"Cross-validation with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    y_train, x_train, ids_train = load_csv_data(data_file)\n",
    "    #x_train, _, _ = standardize(x_train)\n",
    "    # Do the Cross Validation for the ridge regression\n",
    "    min_loss, deg, lamb = cross_validation(y_train, x_train, \n",
    "                                           degrees_lambdas, degrees_poly,\n",
    "                                           k_fold, digits, verbose = True)\n",
    "    # Print some interesting values\n",
    "    print(\"  Max pred = %f\"%(1-min_loss))\n",
    "    print(\"  Lambda* = %10.3e\"%lamb)\n",
    "    print(\"  Degree* = %i\"%deg)\n",
    "    print(\"\\n\")\n",
    "    lambda_star.append(lamb)\n",
    "    degree_star.append(deg)\n",
    "\n",
    "    perc_right_pred += len(y_train)*(1-min_loss)\n",
    "    nbr_labels += len(y_train)\n",
    "    \n",
    "perc_right_pred = perc_right_pred/nbr_labels\n",
    "print(\"Percentage of right pred on training set: %f\"%perc_right_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the results into *pickle* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/degrees_ct.p', 'wb') as pickle_file:\n",
    "    pickle.dump(degree_star, pickle_file)\n",
    "    \n",
    "with open('data/lambdas_ct.p', 'wb') as pickle_file:\n",
    "    pickle.dump(lambda_star, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the results from the *pickle* files (in case we don't want to train again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/degrees.p', 'rb') as pickle_file:\n",
    "    degree_star = pickle.load(pickle_file)\n",
    "    \n",
    "with open('data/lambdas.p', 'rb') as pickle_file:\n",
    "    lambda_star = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(degree_star)\n",
    "print(lambda_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the training (get the weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "mean = 0\n",
    "total = 0\n",
    "ct = [False, True, False, True, True, True, False, True]\n",
    "sqrt = [True, True, True, True, False, True, False, True]\n",
    "square = [False, True, False, True, False, True, True, False]\n",
    "for idx, data in enumerate(TRAINING_DATA):\n",
    "    # Print that we start the training\n",
    "    print(\"Training with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    y_train, x_train, ids_train = load_csv_data(data_file)\n",
    "    \n",
    "    print(lambda_star[idx])\n",
    "    print(degree_star[idx])\n",
    "    \n",
    "    # RR to get the best weights\n",
    "    \"\"\"\n",
    "    if idx%2 == 0:\n",
    "        tX_train = ct_poly(x_train, degree_star[idx])        \n",
    "    elif idx == 7:\n",
    "        tX_train = ct_poly_sqrt(x_train, degree_star[idx])\n",
    "    else:\n",
    "        tX_train = ct_poly_sqrt_squared(x_train, degree_star[idx])\n",
    "    \"\"\"\n",
    "    tX_train = build_poly_cross_terms(x_train, degree_star[idx],\n",
    "                                      ct=ct[idx], sqrt=sqrt[idx], square=square[idx])\n",
    "        \n",
    "    _, w_star = ridge_regression(y_train, tX_train, lambda_star[idx])  \n",
    "    print(tX_train.shape)\n",
    "    val = perc_wrong_pred(y_train, tX_train, w_star)\n",
    "    print(\"Good prediction: %f\"%(100.*(1.-val)))\n",
    "    total += len(y_train)\n",
    "    mean += (1-val)*len(y_train)\n",
    "    \n",
    "    weights.append(w_star)   \n",
    "print(\"Total Good prediction: %f\"%(100*mean/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on the test data to get the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "ids_pred = []\n",
    "\n",
    "for idx, data in enumerate(TEST_DATA):\n",
    "    # Print that we start the testing\n",
    "    print(\"Testing with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    _, x_test, ids_test = load_csv_data(data_file)\n",
    "    # Build the polynomial\n",
    "    tX_test = build_poly_cross_terms(x_test, degree_star[idx], \n",
    "                          ct=ct[idx], sqrt=sqrt[idx], square=square[idx])\n",
    "    \n",
    "    # Predict the labels\n",
    "    y_pred.append(predict_labels(weights[idx], tX_test)) \n",
    "    ids_pred.append(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "pred = []\n",
    "\n",
    "idx = min(ids_pred[:][0])\n",
    "\n",
    "length = np.sum(len(i) for i in y_pred)\n",
    "\n",
    "for i in range(length):\n",
    "    for j in range(len(TEST_DATA)):\n",
    "        if len(ids_pred[j]) > 0:\n",
    "            if ids_pred[j][0] == idx:\n",
    "                ids.append(idx)\n",
    "                pred.append(y_pred[j][0])\n",
    "                ids_pred[j] = np.delete(ids_pred[j], 0)\n",
    "                y_pred[j] = np.delete(y_pred[j], 0)\n",
    "                break\n",
    "\n",
    "    if (i % 100000 == 0):\n",
    "        print(i)\n",
    "        \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(pred))\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "ids = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output/RR_8_models_10_fold_multi_ct.csv' # TODO: fill in desired name of output file for submission\n",
    "create_csv_submission(ids, pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(pred==1)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

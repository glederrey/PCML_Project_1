{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with Ridge Regression (8 models)\n",
    "\n",
    "In this notebook, we will use the functions in the file ridge_regression.py. This time, we will use the 8 data sets and see if the prediction becomes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import display\n",
    "# Import everything in the functions folder\n",
    "from functions.costs import *\n",
    "from functions.helpers import *\n",
    "from functions.split import *\n",
    "#from functions.ridge_regression import *\n",
    "from functions.helpers import *\n",
    "from functions.least_squares_GD import *\n",
    "from functions.logistic_regression import *\n",
    "from functions.regularized_logistic_regression import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "\n",
    "\"\"\"\n",
    "TRAINING_DATA = ['train_jet_0_wout_mass_pca.csv' , 'train_jet_0_with_mass_pca.csv',\n",
    "                 'train_jet_1_wout_mass_pca.csv' , 'train_jet_1_with_mass_pca.csv',\n",
    "                 'train_jet_2_wout_mass_pca.csv' , 'train_jet_2_with_mass_pca.csv',\n",
    "                 'train_jet_3_wout_mass_pca.csv' , 'train_jet_3_with_mass_pca.csv']\n",
    "\n",
    "TEST_DATA = ['test_jet_0_wout_mass_pca.csv' , 'test_jet_0_with_mass_pca.csv',\n",
    "             'test_jet_1_wout_mass_pca.csv' , 'test_jet_1_with_mass_pca.csv',\n",
    "             'test_jet_2_wout_mass_pca.csv' , 'test_jet_2_with_mass_pca.csv',\n",
    "             'test_jet_3_wout_mass_pca.csv' , 'test_jet_3_with_mass_pca.csv']\n",
    "\"\"\"\n",
    "\n",
    "TRAINING_DATA = ['train_jet_0_wout_mass.csv' , 'train_jet_0_with_mass_pca.csv',\n",
    "                 'train_jet_1_wout_mass.csv' , 'train_jet_1_with_mass_pca.csv',\n",
    "                 'train_jet_2_wout_mass.csv' , 'train_jet_2_with_mass_pca.csv',\n",
    "                 'train_jet_3_wout_mass.csv' , 'train_jet_3_with_mass_pca.csv']\n",
    "\n",
    "TEST_DATA = ['test_jet_0_wout_mass.csv' , 'test_jet_0_with_mass_pca.csv',\n",
    "             'test_jet_1_wout_mass.csv' , 'test_jet_1_with_mass_pca.csv',\n",
    "             'test_jet_2_wout_mass.csv' , 'test_jet_2_with_mass_pca.csv',\n",
    "             'test_jet_3_wout_mass.csv' , 'test_jet_3_with_mass_pca.csv']\n",
    "\n",
    "weights = []\n",
    "lambda_star = []\n",
    "degree_star = []\n",
    "y_pred = []\n",
    "ids_pred = []\n",
    "perc_right_pred = 0\n",
    "nbr_labels = 0\n",
    "\n",
    "#degrees_poly = np.arange(1, 14)\n",
    "#degrees_lambdas = np.arange(-10, 5)\n",
    "\n",
    "degrees_poly = np.arange(5,6)\n",
    "degrees_lambdas = np.arange(-2, 5)\n",
    "\n",
    "k_fold = 5\n",
    "digits = 3\n",
    "#(95.1378)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on all the training data.\n",
    "We use CV to find best lambda and best degree and then we use the RR again to get the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with file train_jet_0_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "  Start the 5-fold Cross Validation!\n",
      "  Start degree 5\n",
      "  Start for digit 1\n",
      "    Power of lambda: -2\n",
      "    Power of lambda: -1\n",
      "    Power of lambda: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\regularized_logistic_regression.py:15: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss = calculate_loss(y, tx, w) + lambda_*np.linalg.norm(w)**2\n",
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\regularized_logistic_regression.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if n_iter > 1 and np.abs(losses[-1]-losses[-2]) < 1e-8:\n",
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\regularized_logistic_regression.py:16: RuntimeWarning: overflow encountered in multiply\n",
      "  grad = calculate_gradient(y, tx, w) + 2*lambda_*w\n",
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\logistic_regression.py:20: RuntimeWarning: invalid value encountered in less\n",
      "  result[t<60] = np.log(1+np.exp(result[t<60]))\n",
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\logistic_regression.py:11: RuntimeWarning: invalid value encountered in greater\n",
      "  result[t>60] = 1\n",
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\logistic_regression.py:12: RuntimeWarning: invalid value encountered in less\n",
      "  result[t<-60] = 0\n",
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\logistic_regression.py:13: RuntimeWarning: invalid value encountered in less\n",
      "  result[np.abs(t) < 60] = 1/(1+np.exp(result[np.abs(t) < 60]))\n",
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\logistic_regression.py:26: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (np.sum(log_exp(np.dot(tx,w)))) - np.dot(y.transpose(),np.dot(tx,w))\n",
      "D:\\Users\\glede\\Desktop\\EPFL\\PCML_Project_1\\functions\\regularized_logistic_regression.py:25: RuntimeWarning: invalid value encountered in subtract\n",
      "  w = w-alpha*gradient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Power of lambda: 1\n",
      "    Power of lambda: 2\n",
      "    Power of lambda: 3\n",
      "    Power of lambda: 4\n",
      "    Start for digit 2\n",
      "    Start for digit 3\n",
      "  Finished Degree 5. Best lambda is  3.100e+00 with percentage wrong pred 32.193522\n",
      "  --------------------\n",
      " 5-fold Cross Validation finished!\n",
      "\n",
      "  Max pred = -31.193522\n",
      "  Lambda* =  3.100e+00\n",
      "  Degree* = 5\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ridge_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1d7cca582d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_star\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_star\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ridge_regression' is not defined"
     ]
    }
   ],
   "source": [
    "for data in TRAINING_DATA:\n",
    "    # Print that we start the training\n",
    "    print(\"Training with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    y_train, x_train, ids_train = load_csv_data(data_file)\n",
    "    y_train = y_train[:100]\n",
    "    x_train = x_train[:100,:]\n",
    "    # Do the Cross Validation for the ridge regression\n",
    "    min_loss, deg, lamb = cross_validation(y_train, x_train, \n",
    "                                           degrees_lambdas, degrees_poly,\n",
    "                                           1, 1000,\n",
    "                                           k_fold, digits, verbose = True)\n",
    "    # Print some interesting values\n",
    "    print(\"  Max pred = %f\"%(1-min_loss))\n",
    "    print(\"  Lambda* = %10.3e\"%lamb)\n",
    "    print(\"  Degree* = %i\"%deg)\n",
    "    print(\"\\n\")\n",
    "    lambda_star.append(lamb)\n",
    "    degree_star.append(deg)\n",
    "    # RR to get the best weights\n",
    "    if deg > 1:\n",
    "        tX_train = build_poly(x_train, deg)\n",
    "    else:\n",
    "        tX_train = x_train\n",
    "    _, w_star = ridge_regression(y_train, tX_train, lamb)\n",
    "    weights.append(w_star)\n",
    "    \n",
    "    perc_right_pred += len(y_train)*(1-min_loss)\n",
    "    nbr_labels += len(y_train)\n",
    "    \n",
    "perc_right_pred = perc_right_pred/nbr_labels\n",
    "print(\"Percentage of right pred on training set: %f\"%perc_right_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the results into *pickle* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/weights.p', 'wb') as pickle_file:\n",
    "    pickle.dump(weights, pickle_file)\n",
    "    \n",
    "with open('data/degrees.p', 'wb') as pickle_file:\n",
    "    pickle.dump(degree_star, pickle_file)\n",
    "    \n",
    "with open('data/lambdas.p', 'wb') as pickle_file:\n",
    "    pickle.dump(lambda_star, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the results from the *pickle* files (in case we don't want to train again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/weights.p', 'rb') as pickle_file:\n",
    "    weights = pickle.load(pickle_file)\n",
    "    \n",
    "with open('data/degrees.p', 'rb') as pickle_file:\n",
    "    degree_star = pickle.load(pickle_file)\n",
    "    \n",
    "with open('data/lambdas.p', 'rb') as pickle_file:\n",
    "    lambda_star = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop on the test data to get the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with file test_jet_0_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_0_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_1_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_1_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_2_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_2_with_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_3_wout_mass.csv\n",
      "-----------------------------------------------------\n",
      "Testing with file test_jet_3_with_mass.csv\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(TEST_DATA):\n",
    "    # Print that we start the testing\n",
    "    print(\"Testing with file %s\"%data)\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    # Recreate the file\n",
    "    data_file = DATA_FOLDER + '/' + data\n",
    "    # Load the file\n",
    "    _, x_test, ids_test = load_csv_data(data_file)\n",
    "    # Build the polynomial\n",
    "    if degree_star[idx] > 1:\n",
    "        tX_test = build_poly(x_test, degree_star[idx])\n",
    "    else:\n",
    "        tX_test = x_test\n",
    "    # Predict the labels\n",
    "    y_pred.append(predict_labels(weights[idx], tX_test))\n",
    "    ids_pred.append(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "pred = []\n",
    "\n",
    "idx = min(ids_pred[:][0])\n",
    "\n",
    "length = np.sum(len(i) for i in y_pred)\n",
    "\n",
    "for i in range(length):\n",
    "    for j in range(len(TEST_DATA)):\n",
    "        if len(ids_pred[j]) > 0:\n",
    "            if ids_pred[j][0] == idx:\n",
    "                ids.append(idx)\n",
    "                pred.append(y_pred[j][0])\n",
    "                ids_pred[j] = np.delete(ids_pred[j], 0)\n",
    "                y_pred[j] = np.delete(y_pred[j], 0)\n",
    "                break\n",
    "\n",
    "    if (i % 100000 == 0):\n",
    "        print(i)\n",
    "        \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568238\n",
      "568238\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "ids = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output/RR_8_models_10_fold.csv' # TODO: fill in desired name of output file for submission\n",
    "create_csv_submission(ids, pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32050478848651448"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred==1)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
